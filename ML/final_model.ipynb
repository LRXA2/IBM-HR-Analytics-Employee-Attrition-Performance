{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d861f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "\n",
    "X = pd.read_csv(DATA_PATH + \"X_model_selection.csv\")\n",
    "y = pd.read_csv(DATA_PATH + \"y_model_selection.csv\")\n",
    "\n",
    "with open(DATA_PATH + \"determined_feature_sets.pkl\", \"rb\") as f:\n",
    "    determined_feature_sets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01dbfc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (1028, 19) (221, 19) (221, 19)\n",
      "Pos rates: 0.1605058365758755 0.16289592760180996 0.16289592760180996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score,\n",
    "    accuracy_score, recall_score, precision_score, fbeta_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "y_vec = y.squeeze() if hasattr(y, \"squeeze\") else y\n",
    "if isinstance(y_vec, pd.DataFrame):\n",
    "    y_vec = y_vec.iloc[:, 0]\n",
    "\n",
    "# Train/Val/Test split (70/15/15)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y_vec, test_size=0.15, stratify=y_vec, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.1764706,  # 0.176... of 85% ≈ 15%\n",
    "    stratify=y_trainval, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"Pos rates:\", y_train.mean(), y_val.mean(), y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cfb7e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(estimator, X_part):\n",
    "    \"\"\"Return continuous scores for PR-AUC/ROC-AUC and thresholding.\"\"\"\n",
    "    if hasattr(estimator, \"predict_proba\"):\n",
    "        return estimator.predict_proba(X_part)[:, 1]\n",
    "    if hasattr(estimator, \"decision_function\"):\n",
    "        return estimator.decision_function(X_part)\n",
    "    raise AttributeError(\"Estimator has neither predict_proba nor decision_function\")\n",
    "\n",
    "def pick_threshold_max_f2(y_true, scores, grid_size=200):\n",
    "    thresholds = np.linspace(0.01, 0.99, grid_size)\n",
    "    best_t, best_f2 = 0.5, -1.0\n",
    "    for t in thresholds:\n",
    "        y_pred = (scores >= t).astype(int)\n",
    "        f2 = fbeta_score(y_true, y_pred, beta=2, zero_division=0)\n",
    "        if f2 > best_f2:\n",
    "            best_f2, best_t = f2, t\n",
    "    return float(best_t), float(best_f2)\n",
    "\n",
    "def eval_metrics(y_true, scores, threshold):\n",
    "    y_pred = (scores >= threshold).astype(int)\n",
    "    return {\n",
    "        \"pr_auc\": float(average_precision_score(y_true, scores)),\n",
    "        \"roc_auc\": float(roc_auc_score(y_true, scores)),\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"recall\": float(recall_score(y_true, y_pred, zero_division=0)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "        \"f2\": float(fbeta_score(y_true, y_pred, beta=2, zero_division=0)),\n",
    "        \"tn_fp_fn_tp\": tuple(confusion_matrix(y_true, y_pred).ravel())\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd3a01",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Final evaluation metrics and threshold selection\n",
    "\n",
    "Model performance was evaluated using a combination of **threshold-independent** and **threshold-dependent** metrics to reflect both ranking quality and real-world decision-making.\n",
    "\n",
    "### Threshold-independent metrics\n",
    "\n",
    "* **PR-AUC (Precision–Recall AUC)** was used as the primary metric for model comparison. PR-AUC is well-suited to imbalanced classification problems because it focuses on performance on the minority class and does not depend on a fixed decision threshold.\n",
    "* **ROC-AUC** was reported as a secondary metric to assess overall ranking performance and class separability.\n",
    "\n",
    "These metrics evaluate how well a model ranks attrition cases without committing to a specific classification rule.\n",
    "\n",
    "---\n",
    "\n",
    "### Threshold-dependent metrics\n",
    "\n",
    "For operational use, a fixed decision threshold is required. To evaluate this setting:\n",
    "\n",
    "* **Recall** measures the proportion of actual attrition cases correctly identified and directly reflects the cost of missed attrition events.\n",
    "* **Precision** quantifies the proportion of predicted attrition cases that are correct, reflecting the cost of false positives.\n",
    "* **Accuracy** is reported for completeness but is not relied upon due to class imbalance.\n",
    "\n",
    "---\n",
    "\n",
    "### F2-score and threshold selection\n",
    "\n",
    "The **F2-score** was used as the primary threshold-dependent metric. Unlike F1, F2 places greater emphasis on recall, aligning with the objective of minimizing missed attrition cases while still penalizing excessive false positives.\n",
    "\n",
    "Decision thresholds were selected by **maximizing F2-score on the validation set only**. This ensures that:\n",
    "\n",
    "* threshold selection is aligned with business priorities,\n",
    "* and the test set remains untouched until final evaluation.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bde60d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_tune = {\n",
    "    \"logreg_l2\": (\"linear\",\n",
    "        LogisticRegression(\n",
    "            penalty=\"l2\", solver=\"lbfgs\", class_weight=\"balanced\",\n",
    "            max_iter=5000, random_state=SEED\n",
    "        )\n",
    "    ),\n",
    "    \"logreg_l1\": (\"linear\",\n",
    "        LogisticRegression(\n",
    "            penalty=\"l1\", solver=\"liblinear\", class_weight=\"balanced\",\n",
    "            max_iter=5000, random_state=SEED\n",
    "        )\n",
    "    ),\n",
    "    \"linearsvc\": (\"linear\",\n",
    "        LinearSVC(class_weight=\"balanced\", random_state=SEED)\n",
    "    ),\n",
    "    \"gaussian_nb\": (\"naive_bayes\",\n",
    "        GaussianNB()\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Param grids\n",
    "param_grids = {\n",
    "    \"logreg_l2\": {\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]},\n",
    "    \"logreg_l1\": {\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]},\n",
    "    \"linearsvc\": {\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]},\n",
    "    \"gaussian_nb\": {\"var_smoothing\": [1e-12, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6]},\n",
    "}\n",
    "\n",
    "# CV for tuning\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26b46de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>family</th>\n",
       "      <th>split</th>\n",
       "      <th>threshold</th>\n",
       "      <th>best_params</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f2</th>\n",
       "      <th>tn_fp_fn_tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logreg_l1</td>\n",
       "      <td>linear</td>\n",
       "      <td>test</td>\n",
       "      <td>0.467990</td>\n",
       "      <td>{'C': 0.3}</td>\n",
       "      <td>0.625344</td>\n",
       "      <td>0.823423</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.633484</td>\n",
       "      <td>(136, 49, 8, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linearsvc</td>\n",
       "      <td>linear</td>\n",
       "      <td>test</td>\n",
       "      <td>0.029698</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.617437</td>\n",
       "      <td>0.827177</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.636792</td>\n",
       "      <td>(144, 41, 9, 27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>linear</td>\n",
       "      <td>test</td>\n",
       "      <td>0.458141</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.613357</td>\n",
       "      <td>0.824024</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.337349</td>\n",
       "      <td>0.616740</td>\n",
       "      <td>(130, 55, 8, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gaussian_nb</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>test</td>\n",
       "      <td>0.103568</td>\n",
       "      <td>{'var_smoothing': 1e-07}</td>\n",
       "      <td>0.611212</td>\n",
       "      <td>0.832583</td>\n",
       "      <td>0.656109</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.303922</td>\n",
       "      <td>0.630081</td>\n",
       "      <td>(114, 71, 5, 31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gaussian_nb</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>train</td>\n",
       "      <td>0.103568</td>\n",
       "      <td>{'var_smoothing': 1e-07}</td>\n",
       "      <td>0.631025</td>\n",
       "      <td>0.848330</td>\n",
       "      <td>0.666342</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.308190</td>\n",
       "      <td>0.636121</td>\n",
       "      <td>(542, 321, 22, 143)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>linear</td>\n",
       "      <td>train</td>\n",
       "      <td>0.458141</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.625686</td>\n",
       "      <td>0.853120</td>\n",
       "      <td>0.728599</td>\n",
       "      <td>0.824242</td>\n",
       "      <td>0.352332</td>\n",
       "      <td>0.650096</td>\n",
       "      <td>(613, 250, 29, 136)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linearsvc</td>\n",
       "      <td>linear</td>\n",
       "      <td>train</td>\n",
       "      <td>0.029698</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.622382</td>\n",
       "      <td>0.852607</td>\n",
       "      <td>0.777237</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.401840</td>\n",
       "      <td>0.664300</td>\n",
       "      <td>(668, 195, 34, 131)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logreg_l1</td>\n",
       "      <td>linear</td>\n",
       "      <td>train</td>\n",
       "      <td>0.467990</td>\n",
       "      <td>{'C': 0.3}</td>\n",
       "      <td>0.615694</td>\n",
       "      <td>0.853246</td>\n",
       "      <td>0.742218</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.363388</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>(630, 233, 32, 133)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logreg_l1</td>\n",
       "      <td>linear</td>\n",
       "      <td>val</td>\n",
       "      <td>0.467990</td>\n",
       "      <td>{'C': 0.3}</td>\n",
       "      <td>0.571817</td>\n",
       "      <td>0.808709</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.337349</td>\n",
       "      <td>0.616740</td>\n",
       "      <td>(130, 55, 8, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gaussian_nb</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>val</td>\n",
       "      <td>0.103568</td>\n",
       "      <td>{'var_smoothing': 1e-07}</td>\n",
       "      <td>0.568735</td>\n",
       "      <td>0.809159</td>\n",
       "      <td>0.669683</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0.622407</td>\n",
       "      <td>(118, 67, 6, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>linearsvc</td>\n",
       "      <td>linear</td>\n",
       "      <td>val</td>\n",
       "      <td>0.029698</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.557982</td>\n",
       "      <td>0.809459</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>(140, 45, 10, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>linear</td>\n",
       "      <td>val</td>\n",
       "      <td>0.458141</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.544280</td>\n",
       "      <td>0.806607</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.345679</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>(132, 53, 8, 28)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model       family  split  threshold               best_params  \\\n",
       "5     logreg_l1       linear   test   0.467990                {'C': 0.3}   \n",
       "8     linearsvc       linear   test   0.029698               {'C': 0.01}   \n",
       "2     logreg_l2       linear   test   0.458141                {'C': 0.1}   \n",
       "11  gaussian_nb  naive_bayes   test   0.103568  {'var_smoothing': 1e-07}   \n",
       "9   gaussian_nb  naive_bayes  train   0.103568  {'var_smoothing': 1e-07}   \n",
       "0     logreg_l2       linear  train   0.458141                {'C': 0.1}   \n",
       "6     linearsvc       linear  train   0.029698               {'C': 0.01}   \n",
       "3     logreg_l1       linear  train   0.467990                {'C': 0.3}   \n",
       "4     logreg_l1       linear    val   0.467990                {'C': 0.3}   \n",
       "10  gaussian_nb  naive_bayes    val   0.103568  {'var_smoothing': 1e-07}   \n",
       "7     linearsvc       linear    val   0.029698               {'C': 0.01}   \n",
       "1     logreg_l2       linear    val   0.458141                {'C': 0.1}   \n",
       "\n",
       "      pr_auc   roc_auc  accuracy    recall  precision        f2  \\\n",
       "5   0.625344  0.823423  0.742081  0.777778   0.363636  0.633484   \n",
       "8   0.617437  0.827177  0.773756  0.750000   0.397059  0.636792   \n",
       "2   0.613357  0.824024  0.714932  0.777778   0.337349  0.616740   \n",
       "11  0.611212  0.832583  0.656109  0.861111   0.303922  0.630081   \n",
       "9   0.631025  0.848330  0.666342  0.866667   0.308190  0.636121   \n",
       "0   0.625686  0.853120  0.728599  0.824242   0.352332  0.650096   \n",
       "6   0.622382  0.852607  0.777237  0.793939   0.401840  0.664300   \n",
       "3   0.615694  0.853246  0.742218  0.806061   0.363388  0.648148   \n",
       "4   0.571817  0.808709  0.714932  0.777778   0.337349  0.616740   \n",
       "10  0.568735  0.809159  0.669683  0.833333   0.309278  0.622407   \n",
       "7   0.557982  0.809459  0.751131  0.722222   0.366197  0.604651   \n",
       "1   0.544280  0.806607  0.723982  0.777778   0.345679  0.622222   \n",
       "\n",
       "            tn_fp_fn_tp  \n",
       "5      (136, 49, 8, 28)  \n",
       "8      (144, 41, 9, 27)  \n",
       "2      (130, 55, 8, 28)  \n",
       "11     (114, 71, 5, 31)  \n",
       "9   (542, 321, 22, 143)  \n",
       "0   (613, 250, 29, 136)  \n",
       "6   (668, 195, 34, 131)  \n",
       "3   (630, 233, 32, 133)  \n",
       "4      (130, 55, 8, 28)  \n",
       "10     (118, 67, 6, 30)  \n",
       "7     (140, 45, 10, 26)  \n",
       "1      (132, 53, 8, 28)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = {}\n",
    "metrics_rows = []\n",
    "preds_val_rows = []\n",
    "preds_test_rows = []\n",
    "\n",
    "for model_name, (family, base_est) in models_to_tune.items():\n",
    "    feats = determined_feature_sets[family]\n",
    "    \n",
    "    Xtr = X_train[feats]\n",
    "    Xva = X_val[feats]\n",
    "    Xte = X_test[feats]\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=base_est,\n",
    "        param_grid=param_grids[model_name],\n",
    "        scoring=\"average_precision\",\n",
    "        cv=inner_cv,\n",
    "        n_jobs=16,\n",
    "        verbose=0,\n",
    "        refit=True\n",
    "    )\n",
    "    grid.fit(Xtr, y_train)\n",
    "    best_est = grid.best_estimator_\n",
    "\n",
    "    best_est.fit(Xtr, y_train)\n",
    "    best_models[model_name] = best_est\n",
    "\n",
    "    # Scores\n",
    "    tr_scores = get_scores(best_est, Xtr)\n",
    "    va_scores = get_scores(best_est, Xva)\n",
    "    te_scores = get_scores(best_est, Xte)\n",
    "\n",
    "    best_t, best_f2_val = pick_threshold_max_f2(y_val, va_scores)\n",
    "\n",
    "    for split_name, y_true, scores in [\n",
    "        (\"train\", y_train, tr_scores),\n",
    "        (\"val\",   y_val,   va_scores),\n",
    "        (\"test\",  y_test,  te_scores),\n",
    "    ]:\n",
    "        row = {\n",
    "            \"model\": model_name,\n",
    "            \"family\": family,\n",
    "            \"split\": split_name,\n",
    "            \"threshold\": best_t,\n",
    "            \"best_params\": grid.best_params_,\n",
    "        }\n",
    "        row.update(eval_metrics(y_true, scores, best_t))\n",
    "        metrics_rows.append(row)\n",
    "\n",
    "    preds_val_rows.append(pd.DataFrame({\n",
    "        \"model\": model_name,\n",
    "        \"family\": family,\n",
    "        \"y_true\": y_val.values if hasattr(y_val, \"values\") else y_val,\n",
    "        \"score\": va_scores,\n",
    "        \"threshold\": best_t,\n",
    "        \"y_pred\": (va_scores >= best_t).astype(int),\n",
    "    }))\n",
    "\n",
    "    preds_test_rows.append(pd.DataFrame({\n",
    "        \"model\": model_name,\n",
    "        \"family\": family,\n",
    "        \"y_true\": y_test.values if hasattr(y_test, \"values\") else y_test,\n",
    "        \"score\": te_scores,\n",
    "        \"threshold\": best_t,\n",
    "        \"y_pred\": (te_scores >= best_t).astype(int),\n",
    "    }))\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_rows)\n",
    "\n",
    "preds_val_df = pd.concat(preds_val_rows, ignore_index=True)\n",
    "preds_test_df = pd.concat(preds_test_rows, ignore_index=True)\n",
    "\n",
    "metrics_df.sort_values([\"split\", \"pr_auc\"], ascending=[True, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3764c977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>family</th>\n",
       "      <th>split</th>\n",
       "      <th>threshold</th>\n",
       "      <th>best_params</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f2</th>\n",
       "      <th>tn_fp_fn_tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linearsvc</td>\n",
       "      <td>linear</td>\n",
       "      <td>test</td>\n",
       "      <td>0.029698</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.617437</td>\n",
       "      <td>0.827177</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.636792</td>\n",
       "      <td>(144, 41, 9, 27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logreg_l1</td>\n",
       "      <td>linear</td>\n",
       "      <td>test</td>\n",
       "      <td>0.467990</td>\n",
       "      <td>{'C': 0.3}</td>\n",
       "      <td>0.625344</td>\n",
       "      <td>0.823423</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.633484</td>\n",
       "      <td>(136, 49, 8, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaussian_nb</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>test</td>\n",
       "      <td>0.103568</td>\n",
       "      <td>{'var_smoothing': 1e-07}</td>\n",
       "      <td>0.611212</td>\n",
       "      <td>0.832583</td>\n",
       "      <td>0.656109</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.303922</td>\n",
       "      <td>0.630081</td>\n",
       "      <td>(114, 71, 5, 31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>linear</td>\n",
       "      <td>test</td>\n",
       "      <td>0.458141</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.613357</td>\n",
       "      <td>0.824024</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.337349</td>\n",
       "      <td>0.616740</td>\n",
       "      <td>(130, 55, 8, 28)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model       family split  threshold               best_params  \\\n",
       "0    linearsvc       linear  test   0.029698               {'C': 0.01}   \n",
       "1    logreg_l1       linear  test   0.467990                {'C': 0.3}   \n",
       "2  gaussian_nb  naive_bayes  test   0.103568  {'var_smoothing': 1e-07}   \n",
       "3    logreg_l2       linear  test   0.458141                {'C': 0.1}   \n",
       "\n",
       "     pr_auc   roc_auc  accuracy    recall  precision        f2  \\\n",
       "0  0.617437  0.827177  0.773756  0.750000   0.397059  0.636792   \n",
       "1  0.625344  0.823423  0.742081  0.777778   0.363636  0.633484   \n",
       "2  0.611212  0.832583  0.656109  0.861111   0.303922  0.630081   \n",
       "3  0.613357  0.824024  0.714932  0.777778   0.337349  0.616740   \n",
       "\n",
       "        tn_fp_fn_tp  \n",
       "0  (144, 41, 9, 27)  \n",
       "1  (136, 49, 8, 28)  \n",
       "2  (114, 71, 5, 31)  \n",
       "3  (130, 55, 8, 28)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_leaderboard = (\n",
    "    metrics_df[metrics_df[\"split\"] == \"test\"]\n",
    "    .sort_values([\"f2\", \"recall\", \"pr_auc\"], ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "test_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31632149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>total_positives</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gaussian_nb</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linearsvc</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg_l1</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  true_positives  total_positives    recall\n",
       "0  gaussian_nb              31               36  0.861111\n",
       "1    linearsvc              27               36  0.750000\n",
       "2    logreg_l1              28               36  0.777778\n",
       "3    logreg_l2              28               36  0.777778"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_counts = (\n",
    "    preds_test_df\n",
    "    .query(\"y_true == 1 and y_pred == 1\")\n",
    "    .groupby(\"model\")\n",
    "    .size()\n",
    "    .rename(\"true_positives\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "total_positives = preds_test_df.query(\"y_true == 1\").groupby(\"model\").size()\n",
    "\n",
    "summary = (\n",
    "    tp_counts\n",
    "    .set_index(\"model\")\n",
    "    .join(total_positives.rename(\"total_positives\"))\n",
    "    .assign(\n",
    "        recall=lambda df: df[\"true_positives\"] / df[\"total_positives\"]\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a490e90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>family</th>\n",
       "      <th>split</th>\n",
       "      <th>threshold</th>\n",
       "      <th>best_params</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f2</th>\n",
       "      <th>tn_fp_fn_tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gaussian_nb</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>val</td>\n",
       "      <td>0.103568</td>\n",
       "      <td>{'var_smoothing': 1e-07}</td>\n",
       "      <td>0.568735</td>\n",
       "      <td>0.809159</td>\n",
       "      <td>0.669683</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0.622407</td>\n",
       "      <td>(118, 67, 6, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>linear</td>\n",
       "      <td>val</td>\n",
       "      <td>0.458141</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.544280</td>\n",
       "      <td>0.806607</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.345679</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>(132, 53, 8, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg_l1</td>\n",
       "      <td>linear</td>\n",
       "      <td>val</td>\n",
       "      <td>0.467990</td>\n",
       "      <td>{'C': 0.3}</td>\n",
       "      <td>0.571817</td>\n",
       "      <td>0.808709</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.337349</td>\n",
       "      <td>0.616740</td>\n",
       "      <td>(130, 55, 8, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linearsvc</td>\n",
       "      <td>linear</td>\n",
       "      <td>val</td>\n",
       "      <td>0.029698</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.557982</td>\n",
       "      <td>0.809459</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>(140, 45, 10, 26)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model       family split  threshold               best_params  \\\n",
       "0  gaussian_nb  naive_bayes   val   0.103568  {'var_smoothing': 1e-07}   \n",
       "1    logreg_l2       linear   val   0.458141                {'C': 0.1}   \n",
       "2    logreg_l1       linear   val   0.467990                {'C': 0.3}   \n",
       "3    linearsvc       linear   val   0.029698               {'C': 0.01}   \n",
       "\n",
       "     pr_auc   roc_auc  accuracy    recall  precision        f2  \\\n",
       "0  0.568735  0.809159  0.669683  0.833333   0.309278  0.622407   \n",
       "1  0.544280  0.806607  0.723982  0.777778   0.345679  0.622222   \n",
       "2  0.571817  0.808709  0.714932  0.777778   0.337349  0.616740   \n",
       "3  0.557982  0.809459  0.751131  0.722222   0.366197  0.604651   \n",
       "\n",
       "         tn_fp_fn_tp  \n",
       "0   (118, 67, 6, 30)  \n",
       "1   (132, 53, 8, 28)  \n",
       "2   (130, 55, 8, 28)  \n",
       "3  (140, 45, 10, 26)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_leaderboard = (\n",
    "    metrics_df[metrics_df[\"split\"] == \"val\"]\n",
    "    .sort_values([\"f2\", \"recall\", \"pr_auc\"], ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "val_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b88e2f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>total_positives</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gaussian_nb</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linearsvc</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg_l1</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logreg_l2</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  true_positives  total_positives    recall\n",
       "0  gaussian_nb              30               36  0.833333\n",
       "1    linearsvc              26               36  0.722222\n",
       "2    logreg_l1              28               36  0.777778\n",
       "3    logreg_l2              28               36  0.777778"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_counts = (\n",
    "    preds_val_df\n",
    "    .query(\"y_true == 1 and y_pred == 1\")\n",
    "    .groupby(\"model\")\n",
    "    .size()\n",
    "    .rename(\"true_positives\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "total_positives = preds_val_df.query(\"y_true == 1\").groupby(\"model\").size()\n",
    "\n",
    "summary = (\n",
    "    tp_counts\n",
    "    .set_index(\"model\")\n",
    "    .join(total_positives.rename(\"total_positives\"))\n",
    "    .assign(\n",
    "        recall=lambda df: df[\"true_positives\"] / df[\"total_positives\"]\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c363d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Final model selection\n",
    "\n",
    "Final model selection was based **exclusively on validation performance**, with the test set reserved for a one-time confirmation of generalization.\n",
    "\n",
    "### Validation-based decision\n",
    "\n",
    "Using the validation set:\n",
    "\n",
    "* **Gaussian Naive Bayes** achieved the **highest F2-score** and **highest recall**\n",
    "* It correctly identified **30 out of 36 attrition cases** (83.3% recall)\n",
    "* Other linear models identified between **26–28** attrition cases\n",
    "\n",
    "Because the primary objective is to **minimize missed attrition events**, validation recall and F2-score were prioritized over precision and accuracy.\n",
    "\n",
    "| Model       | Validation Recall | Validation F2 | True Positives |\n",
    "| ----------- | ----------------- | ------------- | -------------- |\n",
    "| GaussianNB  | **0.833**         | **0.622**     | **30 / 36**    |\n",
    "| LogReg (L2) | 0.778             | 0.622         | 28 / 36        |\n",
    "| LogReg (L1) | 0.778             | 0.617         | 28 / 36        |\n",
    "| LinearSVC   | 0.722             | 0.605         | 26 / 36        |\n",
    "\n",
    "GaussianNB consistently missed the **fewest attrition cases**, aligning most closely with the stated business objective.\n",
    "\n",
    "---\n",
    "\n",
    "### Test set confirmation\n",
    "\n",
    "The test set was used only to verify that the selected model generalizes:\n",
    "\n",
    "* GaussianNB achieved **86.1% recall** on the test set\n",
    "* It correctly identified **31 out of 36 attrition cases**\n",
    "* No performance collapse or instability was observed\n",
    "\n",
    "Differences in ranking between validation and test sets are expected due to sampling variability and threshold sensitivity and were **not** used for model selection.\n",
    "\n",
    "---\n",
    "\n",
    "### Final choice\n",
    "\n",
    "Based on:\n",
    "\n",
    "* superior validation recall and F2-score,\n",
    "* stable performance across splits,\n",
    "* and alignment with business priorities,\n",
    "\n",
    "**Gaussian Naive Bayes was selected as the final model**.\n",
    "\n",
    "This choice prioritizes minimizing missed attrition events while maintaining competitive overall performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations and potential improvements\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. **Limited sample size and class imbalance**\n",
    "   Attrition events constitute a relatively small portion of the dataset. As a result, evaluation metrics—especially recall and F2-score—can vary noticeably across validation and test splits. While this is expected, it limits the statistical certainty of small performance differences between top models.\n",
    "\n",
    "2. **Fixed decision threshold**\n",
    "   A single decision threshold was selected to maximize F2-score on the validation set. In practice, optimal thresholds may vary over time or across departments depending on organizational capacity to act on predictions.\n",
    "\n",
    "3. **Simplified cost assumptions**\n",
    "   The analysis assumes that false negatives (missed attrition) are more costly than false positives. However, no explicit cost function was available, so trade-offs were evaluated using proxy metrics (recall and F2-score).\n",
    "\n",
    "4. **Feature engineering scope**\n",
    "   Feature selection relied on stability across folds and model families. While this improves robustness, more expressive features (e.g., temporal trends or interaction terms) were not explored.\n",
    "\n",
    "5. **Probability calibration**\n",
    "   Some models (e.g., LinearSVC) do not produce calibrated probabilities. While this does not affect ranking metrics, it may limit interpretability when predicted scores are used directly by stakeholders.\n",
    "\n",
    "---\n",
    "\n",
    "### Potential improvements\n",
    "\n",
    "1. **Cost-sensitive learning**\n",
    "   Incorporating an explicit cost matrix or utility-based objective could align model optimization more directly with real business consequences.\n",
    "\n",
    "2. **Threshold optimization by operational constraints**\n",
    "   Instead of maximizing F2-score alone, thresholds could be chosen based on constraints such as maximum allowable follow-ups or minimum recall requirements.\n",
    "\n",
    "3. **Probability calibration and uncertainty estimation**\n",
    "   Applying calibration techniques (e.g., Platt scaling or isotonic regression) would improve the interpretability of predicted attrition probabilities.\n",
    "\n",
    "4. **Richer feature representations**\n",
    "   Including temporal features (e.g., changes in satisfaction or workload over time) or interaction terms may improve predictive performance beyond static attributes.\n",
    "\n",
    "5. **External validation**\n",
    "   Evaluating the model on data from a different time period or organizational unit would provide stronger evidence of generalization.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
